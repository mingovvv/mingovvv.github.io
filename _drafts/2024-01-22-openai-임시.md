---
title: Helm 정리하기
author: mingo
date: 2024-01-08 00:30:00 +0900
categories: [Kubernetes, Helm]
tags: [helm, kubernetes, k8s]
#image:
#  path: /path/to/image
#  alt: image alternative text
---

-----------------

Text Generation은 OpenAI의 텍스트 생성 모델을 의미합니다.
Text Generation은 LLM으로도 불리우며 자연어, 코드 및 이미지를 이해하도록 반복 훈련되었으며 사용자의 입력에 대한 응답으로 텍스트를 출력을 제공합니다.
이러한 Text Generation에 대한 사용자의 입력을 "프롬프트"라고 부르기도 합니다.
이제 이 사용자의 입력을 의미하는 프롬프트 작성 방식에 따라 응답 텍스트의 퀄리티가 천차만별이기 때문에 "프롬프트 엔지니어링" 분야는 중요한 분야가 되어가고 있습니다.

OpenAI 다큐먼트에 의하면 Text Generation은 문서 초안 작성, 코드 작성, 사용자 질문에 대한 답변, 텍스트 분석 및 요약, 다양한 주제에 대한 튜터링, 언어 번역 등 여러가지 상황과 환경에 응용될 수 있다고 합니다.

OpenAI가 제공하는 Text Generation API와 기능을 간단하게 소개하겠습니다.

레거시 모델을 지원하는 컴플리션API와 gpt-3.5-turbo, gpt-4, gtp-4-turbo를 지원하는 챗컴플리션API 두 가지가 있습니다.

레거시 모델의 컴플리션API의 경우 23년 7월 마지막 업데이트가 진행되었고 더 이상 업데이트가 예정되어 있지 않기 때문에 신규 모델을 지원하는 챗컴플리션API 기준으로 소개하겠습니다.

아래 OpenAI 챗컴플리션API를 사용한 간단한 파이썬 코드가 있습니다.
코드를 살펴보면,
바디 파라미터에 Text Generation 모델을 지정해주고 메시지 파라미터가 배열 타입으로 작성된 것을 볼 수 있습니다.
메시지 파라미터는 Role과 Content로 구성되어 있고 대화의 흐름대로 나열되어 있습니다.

여기서 Role 즉 역할의 value로 사용될 수 있는 값은 시스템, 유저, 어시스턴트 3가지 타입입니다.

시스템 롤은 어시스턴트 즉, 사용자의 질의에 대답하는 GPT의 응답을 위해 사전설정 하는 부부입니다. 어시스턴트 성격을 수정하거나 대화 전반에 걸쳐 어시스턴트가 어떻게 행동해야하는지에 대한 구체적인 가이드라인을 작성합니다.
그렇기 때문에 시스템 롤은 일반적으로 메시지 배열에서 첫번째 위치하고 이어서 유저 롤과 어시스턴트 롤이 교대로 위치합니다.

유저 롤은 사용자가 GPT에게 질문 또는 요청하는 컨텐츠를 담는 역할입니다.

어시스턴트 룰은 GPT가 사용자의 질문 또는 요청에 대한 답변을 담고 있습니다.

유저 롤에서 이전 메시지를 참조해야만 하는 질문 또는 요청을 한다면 꼭 대화의 흐름을 배열로 작성해주어야 합니다.
작성된 예시처럼 "대한민군은?" 이라는 텍스트에 반응해서 GPT가 답변할 수 있는 것은 위 대화의 기록을 역할과 컨텐츠를 포함한 메시지 배열로 작성해서 요청했기 때문입니다.
GPT는 요청된 내용을 요약하고 문맥을 파악해서 단순하게 마지막 질문인 "대한민국은?" 이라는 질문이 "2002년 대한민국 월드컵 성적은 어땠니?" 라는 질문의 의도를 파악한 것입니다.

GPT의 챗컴플리션API 요청은 건바이건으로 이루어지기 때문에 과거 요청에 대한 기억이 없습니다. 모든 관련 정보는 요청 시, 대화의 기록의 일부로 제공되어야만 합니다.
하지만 모델마다 요청할 수 있는 토큰 리미트가 존재하기 때문에 토큰 리미트를 파악하고 대화 기록이 토큰 리미트를 넘어선다면 메시지를 압축하던지, 요약하던지, 불필요한 대화를 생략하던지 여러가지 방법으로 토큰 사용량을 줄여서 요청해야 합니다.

===

이어서 JSON mode에 대해서 살펴보겠습니다.

JSON 모드는 간단합니다. 사용자의 질의문에 대한 모든 답변을 JSON 형식으로 강제화하는 기능입니다.
JSON 모드가 등장하기 이전에는 시스템 롤 메시지를 작성할 때 "모든 답변은 JSON 형식으로 포맷팅하고 답변해줘" 라고 작성하곤 했지만 이 방법이 100% JSON 형식으로 답변하는 것을 보장하는 것은 아니였습니다.

항상 JSON 형식의 답변이 필요한 사용자의 경우 큰 불편함이 있었고 이것을 개선하기 위해 JSON 모드가 등장했습니다.
response_format 파라미터에 { "type": "json_object" }를 추가하고 시스템 롤 메시지로 "JSON 출력을 원한다" 명시해주면 JSON 모드는 활성화 됩니다.
현재 gpt-3.5-turbo-1106, gpt-4-1106-preview 모델에서 사용할 수 있는 기능입니다.

JSON 모드가 활성화되면 사용자 질의문에 대한 답변은 항상 JSON 형식으로 이루어진 문자열만 생성되는 것을 보장합니다. 다만 JSON 모드는 구문 오류없이 JSON 형식으로 출력되는 것을 보장하는 것이지 특정 스키마와 일치한다는 것은 보장하지 않습니다.

===

리프로듀시블 아웃풋 기능을 말씀드리겠습니다.

이 기능은 이름에서 알 수 있듯이 "출력물의 재생산"을 의미합니다.
일반적으로 챗컴플리션API는 동일한 질의문에도 요청마다 응답값이 다를 수 있다는 특징이 있습니다.
이것을 비결정적 알고리즘이라고 하고 모델은 인간의 언어를 이해하고 이해한 내용을 바탕으로 새로운 문장을 생성합니다.
이 과정에서 GPT와 같은 모델은 확률적인 방식으로 다음 단어를 선택하기 때문에 항상 같은 출력을 보장하지 않는 것입니다.

이러한 특징으로 인하여 더 자연스러운 대화가 이루어지긴 하지만 동일한 질문에는 동일한 답변이 필요한 경우를 위해 새롭게 베타 기능으로 추가된 것이 "리프로듀시블 아웃풋" 입니다.

사용 방법은 "seed" 라는 파라미터를 추가하고 값으로 임의의 정수값을 설정합니다.

다음 요청 시, "seed" 파라미터에 설정한 정수값과 그 외 모든 요청 파라미터 값이 동일한 경우 GPT는 "리프로듀시블 아웃풋" 기능이 동작하여 동일한 출력값을 보장합니다.

===

그 외 응답값을 튜닝할 수 있는 파라미터를 추가로 말씀드리겠습니다.

프리퀀시 페널티는 동일한 단어가 사용되는 것을 피하도록 도와주는 설정입니다.
프레젠트 페널티는 다양한 단어기 사용하도록 권장하는 설정입니다.

단어, 구문 토큰마다 로지트라는 점수가 있고 이 로지트 점수가 직접적으로 토큰 샘플링에 사용되는 확률은 아니지만 확률을 계산하는 배이스가 됩니다.
어느 대화의 흐름속에서 사과라는 단어의 로지트 점수가 100이고 오렌지라는 단어의 로지트 점수가 50이라면 사과라는 단어가 다음 단어로 선택될 가능성이 높게됩니다.

프리퀀시 페널티는 대화에서 등장한 단어의 횟수만큼 페널티를 부과하는 방식이고 등장할 때마다 로지트 점수를 감소시킵니다.
반면 프로젠트 페널티는 대화에서 등장했는지 안했는지의 여부가 중요하기 때문에 한번이라도 등장하면 딱 1회 로지트 점수를 감소시킵니다. 재등장하여도 추가 페널티가 받는 경우는 없습니다.

프리퀀시 페널티와 프리젠스 페널티를 사용하면 반복적인 문자, 구문 토큰이 샘플링에 선택될 가능성을 줄일 수 있습니다.
문서에 따르면 반복적인 토큰 샘플링을 어느정도 줄이는 정도의 합리적인 페널티 값은 0.1~1 사이로 가이드해주고 있으며 그 이상 페널티 값을 올리면 샘플링 품질이 눈에 띄게 저하된다고 하니 주의하여 사용해야하는 부분입니다.

temperature는 단어를 선택할 때 임의성을 제어하는 설정입니다.
temperature값이 낮으면 텍스트가 더 예측이 가능하고 일관성이 있게되며 값이 높으면 더 자율성과 창의성을 허용하게 됩니다.

===

마지막으로 펑션 콜링에 대해서 알아보겠습니다.
펑션콜링은 23년 6월에 발표된 기능으로 사용자가 "tools" 라는 파라미터를 사용하여 대화를 호출할 때, function 목록을 제공하면 GPT 모델의 자율적인 판단하에
function을 사용하는 것입니다. 이 기능은 GPT의 능력을 외부 도구나 API 연동까지 확장시켜줍니다.

예를 들어 23년 4월까지의 데이터로 학습이되어 있는 GPT4.0이 오늘 날씨를 "오늘 서울의 날씨는?" 이라는 질문에 대답할 수 있는건 내부적으로 펑션콜링 기능을 사용하여 외부 API 호출을 통해 데이터를 조회한 뒤 가공하여 정확한 텍스트를 생성해내고 있는 것입니다.

실제 직원들의 이름, 나이, 급여를 Restful API로 제공해주는 테스트 더미 사이트를 호출하는 펑션을 만들고 GPT에게 제공한 뒤,
"직원들중에 제일 많은 연봉을 받는 사람 이름을 알려줘"
"직원의 평균 나이를 알려줘"
"직원의 이름을 내림차순으로 알려줘"
등 다양한 질문을 정확하게 대답하는 것을 확인했습니다.

이 기능에는 잠재적인 위험도 따릅니다. 사용자를 대신하여 세상에 영향을 미치는 조치(이메일 전송, 온라인 게시, 구매 등)를 수행하기 전에 사용자 확인 흐름을 구축하는 것이 좋습니다.
